val x = (1 to 10).toList
x: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

scala> val numbersDf = x.toDF("number")
numbersDf: org.apache.spark.sql.DataFrame = [number: int]

scala> numbersDf.rdd.partitions.size
res0: Int = 8

scala> numbersDf.write.csv("outputc")
[Stage 0:>                                                          (0 + 8) / 8                                                                                

//coalesce

scala> val numbersDf2 = numbersDf.coalesce(2)
numbersDf2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [number: int]

scala> numbersDf.rdd.partitions.size
res2: Int = 8

scala> numbersDf2.rdd.partitions.size
res3: Int = 2

scala> numbersDf2.write.csv("outputc2")

s

//Repartition

scala> val bartDf = numbersDf.repartition(6)
bartDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [number: int]

scala> bartDf.rdd.partitions.size 
res6: Int = 6
